{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce4e8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 37254/37254 [00:05<00:00, 7205.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 26090\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 17389\n",
      "단어 집합에서 희귀 단어의 비율: 66.65005749329245\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.564717917711491\n",
      "17389\n",
      "8702\n"
     ]
    }
   ],
   "source": [
    "from nltk import Text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords  \n",
    "import urllib.request\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "train_data = pd.read_table('title_output.txt',encoding='ANSI')\n",
    "c=[]\n",
    "train_data['title'].nunique()\n",
    "train_data.drop_duplicates(subset=['title'], inplace=True)\n",
    "for x in range(len(train_data)):\n",
    "    train_data['title'].iloc[x]=re.sub(r'[^a-zA-Z?{1,3} ]', '',str(train_data['title'].iloc[x]))\n",
    "\n",
    "train_data['title'].replace('', np.nan, inplace=True)\n",
    "stop_words = set(stopwords.words('english')) \n",
    "X_train = []\n",
    "for sentence in tqdm(train_data['title']):\n",
    "    tokenized_sentence = word_tokenize(str(sentence)) # 토큰화\n",
    "    for x in range(len(tokenized_sentence)):\n",
    "        if tokenized_sentence[x]=='?':\n",
    "            stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stop_words]\n",
    "            c.append(stopwords_removed_sentence)\n",
    "            break;\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stop_words] # 불용어 제거\n",
    "    X_train.append(stopwords_removed_sentence)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print(rare_cnt)\n",
    "print(vocab_size)\n",
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "647a44e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "558d4b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?',\n",
       " 'bitcoin',\n",
       " ',',\n",
       " 'i',\n",
       " 'btc',\n",
       " '1',\n",
       " 'buy',\n",
       " 'crypto',\n",
       " 'the',\n",
       " 'is',\n",
       " 'what',\n",
       " 'money',\n",
       " 'how',\n",
       " 'wallet',\n",
       " 'like',\n",
       " 'get',\n",
       " 'sell',\n",
       " 'best',\n",
       " 'new',\n",
       " 'price',\n",
       " 'free',\n",
       " 'time',\n",
       " 'help',\n",
       " 'scam',\n",
       " 'why',\n",
       " 'would',\n",
       " 'people',\n",
       " '3',\n",
       " 'this',\n",
       " 'us',\n",
       " 'anyone',\n",
       " 'one',\n",
       " 'market',\n",
       " 'to',\n",
       " 'bitcoins',\n",
       " 'mining',\n",
       " 'good',\n",
       " 'way',\n",
       " 'a',\n",
       " 'if',\n",
       " 'know',\n",
       " 'think',\n",
       " 'make',\n",
       " 'you',\n",
       " 'amp',\n",
       " 'it',\n",
       " 'coinbase',\n",
       " 'k',\n",
       " 'need',\n",
       " 'can',\n",
       " 'cryptocurrency',\n",
       " 'want',\n",
       " 'please',\n",
       " 'going',\n",
       " 'worth',\n",
       " 'first',\n",
       " 'use',\n",
       " 'dont',\n",
       " 'could',\n",
       " 'trading',\n",
       " 'exchange',\n",
       " 'will',\n",
       " 'today',\n",
       " 'im',\n",
       " 'go',\n",
       " 'question',\n",
       " 'earn',\n",
       " 'value',\n",
       " 'still',\n",
       " 'in',\n",
       " 'pay',\n",
       " 'lost',\n",
       " 'much',\n",
       " 'years',\n",
       " 'are',\n",
       " 'world',\n",
       " 'day',\n",
       " 'using',\n",
       " 'back',\n",
       " 'someone',\n",
       " 'got',\n",
       " 'next',\n",
       " 'do',\n",
       " 'for',\n",
       " 'buying',\n",
       " 'bank',\n",
       " 'no',\n",
       " 'network',\n",
       " 'see',\n",
       " 'guys',\n",
       " 'and',\n",
       " 'says',\n",
       " 'right',\n",
       " 'we',\n",
       " 'investment',\n",
       " 'blockchain',\n",
       " 'cash',\n",
       " 'gold',\n",
       " 'currency',\n",
       " 'app',\n",
       " 'coin']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index)[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b942d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
